{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigscience/bloom-560m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avsolatorio/Library/Caches/pypoetry/virtualenvs/llm-lang-b0VyPkoq-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from llm_lang.utils import get_dataset, get_tokens, get_token_stats, get_data_column\n",
    "\n",
    "ds = get_dataset(lang=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
    "bloom_tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
    "\n",
    "# bloom_tokenizer.add_bos_token = True  # This is not supported by the tokenizer, so we have to add it manually below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Add a bos token so we can compute the conditional likelihood of a sentence starting with nothing\n",
    "tokenizer.add_bos_token = True\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Monday, scientists from the Stanford University School of Medicine announced the invention of a new diagnostic tool that can sort cells by type: a tiny printable chip that can be manufactured using standard inkjet printers for possibly about one U.S. cent each.\n"
     ]
    }
   ],
   "source": [
    "# input_text = 'सोमवार को, स्टैनफ़ोर्ड यूनिवर्सिटी स्कूल ऑफ़ मेडिसिन के वैज्ञानिकों ने एक नए डायग्नोस्टिक उपकरण के आविष्कार की घोषणा की जो कोशिकाओं को उनके प्रकार के आधार पर छाँट सकता है: एक छोटी प्रिंट करने योग्य चिप जिसे स्टैण्डर्ड इंकजेट प्रिंटर का उपयोग करके लगभग एक अमेरिकी सेंट के लिए निर्मित किया जा सकता है.'\n",
    "# input_text = get_data_column(ds, \"hin_Deva\")[0]\n",
    "# input_text = get_data_column(ds, \"ace_Arab\")[0]\n",
    "# input_text = get_data_column(ds, \"bel_Cyrl\")[0]\n",
    "# input_text = get_data_column(ds, \"kat_Geor\")[0]\n",
    "input_text = get_data_column(ds, \"eng_Latn\")[0]\n",
    "# input_text = get_data_column(ds, \"tgl_Latn\")[0]\n",
    "\n",
    "print(input_text)\n",
    "\n",
    "bos = bloom_tokenizer(bloom_tokenizer.bos_token, return_tensors='pt')\n",
    "encoded_input = bloom_tokenizer(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     1,   5534,  69629,     15,  92416,   1485,    368, 112640,  13378,\n",
       "          28087,    461,  78971,  57774,    368,  28595,    461,    267,   2084,\n",
       "          51130,  22489,    861,   1400,   5322,  13953,   1331,  47054,    267,\n",
       "          77941,    643, 214564,  53780,    861,   1400,    722, 175640,   3936,\n",
       "          16577,  44072,   3367,   7380,    525,    613,  48825,   3638,   2592,\n",
       "            764,     17,     54,     17,   2538,   5546,     17]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"] = torch.concat([bos[\"input_ids\"], encoded_input[\"input_ids\"]], dim=1)\n",
    "encoded_input[\"attention_mask\"] = torch.concat([bos[\"attention_mask\"], encoded_input[\"attention_mask\"]], dim=1)\n",
    "\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14960450098928835,\n",
       " -3.4218738736388716,\n",
       " [-8.767157554626465,\n",
       "  -9.427632331848145,\n",
       "  -1.0896586179733276,\n",
       "  -11.044292449951172,\n",
       "  -2.226774215698242,\n",
       "  -1.0207033157348633,\n",
       "  -5.899941444396973,\n",
       "  -0.7607376575469971,\n",
       "  -1.7424187660217285,\n",
       "  -0.014853817410767078])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq_len in range(1, 20):  # encoded_input[\"input_ids\"].shape[1]):\n",
    "        _encoded_input = dict(\n",
    "            input_ids=encoded_input[\"input_ids\"][:, :seq_len],\n",
    "            attention_mask=encoded_input[\"attention_mask\"][:, :seq_len],\n",
    "        )\n",
    "\n",
    "        output = bloom(**_encoded_input)\n",
    "        log_prob = nn.Softmax(dim=-1)(output.logits)[0][-1].log()\n",
    "\n",
    "        log_probs.append(log_prob[encoded_input[\"input_ids\"][0, seq_len]].item())\n",
    "\n",
    "np.exp(log_probs[-1]), np.mean(log_probs), log_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-31.78192901611328, -2.8252975940704346]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' sa'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_tokenizer.decode([log_prob.exp().argmax().item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Noong Lunes, inanunsiyo ng mga siyentipiko mula sa Stanford University School of Medicine ang imbensyon ng panibagong kagamitan sa pag-diagnose na makakauri sa mga cell ayon sa uri: isang maliit na chip na maaaring maprint na maaaring magawa gamit ang standard inkjet na mga printer at posibleng nasa isang U.S. sentimo kada isa'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_tokenizer.decode(encoded_input[\"input_ids\"][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4882468870905477"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_probs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24645011850618206"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_probs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-201.52620968595147"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-297.2635999247432"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.631872419901985"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_tokenizer.decode([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"][0, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lang-b0VyPkoq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
